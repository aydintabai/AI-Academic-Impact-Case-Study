{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you lost points on the last checkpoint you can get them back by responding to TA/IA feedback**  \n",
    "\n",
    "Update/change the relevant sections where you lost those points, make sure you respond on GitHub Issues to your TA/IA to call their attention to the changes you made here.\n",
    "\n",
    "Please update your Timeline... no battle plan survives contact with the enemy, so make sure we understand how your plans have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Sandra Gomez\n",
    "- Aydin Tabatabai\n",
    "- Brandon Ng\n",
    "- Sophia Yu\n",
    "- Aarya Patel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What factors have the greatest impact on the popularity of Japanese animation (anime)? Is it through the author, animation company, genre, episode count, or whether it’s done airing or still running? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anime became popular in the 80s internationally but it wasn't until the 90s and early 2000s that it gained traction in the United States with shows like Pokemon, Dragon Ball and Sailor Moon being aired on television.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1)  Now platforms like Netflix, Crunchyroll and other streaming services make it easier for fans of the medium to come together. On this topic, we know that One Piece was the best-selling manga series from 2008 until 2018.<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) We then wondered if the One Piece anime was one of the most watched anime in the recent decade. Was it possible that its 1,000 chapter manga and 1094 episode adaptation (and counting!) allured audiences? Or was its length an outlier among other successful animes? This made us want to specifically investigate what are the specific trends between the most popular anime today. Does it matter how old the anime is, how long or if it's ongoing for it to have a high ranking among popularity? \n",
    "\n",
    "Themarysue.com investigates how anime became more accessible to foreign audiences through the internet.<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3) This could be helpful to our project to see if popularity is affected by the year of release. There could be an argument that the internet is a massive factor in the ever-increasing sales. The article states that at first when the internet was first developing people would pirate content (although it was not easy) which eventually led the Japanese production companies to provide their animations for simulcasting. Now international audiences can keep up with local audiences which could increase a sense of community and the number of loyal fans. Thus popularity would be affected. \n",
    "  \n",
    "Themedialab.me investigates how streaming services have changed video media popularity by addressing seven key factors behind Netflix's popularity as a streaming service.<a name=\"cite_ref-4\"></a>[<sup>4</sup>](#cite_note-4) It would beat out even using television broadcasting for views. It concluded that being flexible, personalized, containing variety, and using technology to its advantage allowed it to become successful. Another website, cosmopolitan.com, tracked the most-watched Netflix series of all time in February 2024. <a name=\"cite_ref-5\"></a>[<sup>5</sup>](#cite_note-5) And it is true, every show mentioned (Wednesday, Stranger Things, Dahmer – Monster, Bridgerton, etc.) had similar genres (supernatural, horror, historical) but were all targeting very different demographics. This is different to anime where the demographics also act like a genre which means that we can generalize some of the themes in the anime as we have not read every single item in the data we collected. However, we believe that there is still uniqueness within these animes and so if we find that a genre trends more than the other we can assume that it is trending because there are a lot of unique storylines. Just like how though Wednesday and Stranger Things both have supernatural elements, they are very different experiences. This would show that as anime streaming is more flexible and personal to the viewer’s interests then it is more accurate to what fans actually enjoy. Not just what companies thought would do well with international audiences.  \n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) D'souza, D. (05 Jun 2023) How did Anime go from Nerdy Cringey to mainstream Pop-Culture?. *LinkedIn*. https://www.linkedin.com/pulse/how-did-anime-go-from-nerdy-cringey-mainstream-deepa-d-souza/ \n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Loo, E. (04 Dec 2009) 2009's Top-Selling Manga in Japan, by Series. *Anime News Network*. https://www.animenewsnetwork.com/news/2009-12-04/2009-top-selling-manga-in-japan-by-series \n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) Polo, S. (04 Jun 2014) Technology and Anime, a Beautiful Love Story. *The Mary Sue*. https://www.themarysue.com/technology-anime-history/ \n",
    "4. <a name=\"cite_note-4\"></a> [^](#cite_ref-4) 7 Key Factors Behind The Success Story Of Netflix. *The Media lab*. https://www.themedialab.me/7-key-factors-behind-success-story-netflix/ \n",
    "5. <a name=\"cite_note-5\"></a> [^](#cite_ref-5) Venn, L. (08 Feb 2024) Netflix: The most watched TV series' of all time. *Cosmopolitan*. https://www.cosmopolitan.com/uk/entertainment/g42176068/netflix-most-watched/ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We believe that publisher and demographic/genre will be strong factors correlating with high popularity in anime. For example, more established publishing companies could be more likely to have a consistent fanbase from previous works, certain demographics might be more targeted (thus leading to higher views), and certain genres could tend to attract more viewers than others, correlating to higher popularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "- Dataset #1\n",
    "  - Dataset Name: Anilist API\n",
    "  - Link to the dataset: https://github.com/AniList/ApiV2-GraphQL-Docs?tab=readme-ov-file\n",
    "  - Number of observations: 1500\n",
    "  - Number of variables: 69\n",
    "\n",
    "Anilist API is an API that provides quick and powerful access to over 500k anime and manga entries. Key categories in the schema including media, mediatrend, character, staff, and live airing data which contain important variables within each schema like anime name, release date, ranking, and popularity. The data types range from categorical variables, such as anime name, genres, and type, to numerical metrics like ranking, number of episodes, and popularity. Variables may serve as proxies for audience preferences and content popularity through genres, average scores of likes, popularity, and ranking. To wrangle and preprocess the dataset, tasks may involve quering the API to access the data, standardizing data formats, ensuring consistency in naming conventions, and handling missing values, especially when certain animes only have Japanese names and no English name. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anilist API Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonng/Library/Python/3.8/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching Data from API and Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m all_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvariables\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     64\u001b[0m         data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/urllib3/connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/http/client.py:1344\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1343\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1344\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/http/client.py:307\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 307\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/http/client.py:268\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 268\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "url = 'https://graphql.anilist.co'\n",
    "\n",
    "query = '''\n",
    "query ($id: Int, $page: Int, $perPage: Int, $search: String) {\n",
    "    Page (page: $page, perPage: $perPage) {\n",
    "        pageInfo {\n",
    "            total\n",
    "            currentPage\n",
    "            lastPage\n",
    "            hasNextPage\n",
    "            perPage\n",
    "        }\n",
    "        media (id: $id, search: $search, type: ANIME) {\n",
    "            title {\n",
    "                romaji\n",
    "                english\n",
    "            }\n",
    "            startDate {\n",
    "                year\n",
    "                month\n",
    "            }\n",
    "            endDate {\n",
    "                year\n",
    "                month\n",
    "            }\n",
    "            season\n",
    "            seasonYear\n",
    "            tags {\n",
    "                name\n",
    "            }\n",
    "            format\n",
    "            status\n",
    "            episodes\n",
    "            genres\n",
    "            popularity\n",
    "            averageScore\n",
    "            countryOfOrigin\n",
    "            source\n",
    "            studios {\n",
    "                edges {\n",
    "                    node {\n",
    "                        name\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            rankings {\n",
    "                rank\n",
    "            }\n",
    "\n",
    "        }\n",
    "    }\n",
    "}\n",
    "'''\n",
    "variables = {\n",
    "    'page': 1,\n",
    "    'perPage': 50\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "\n",
    "while True:\n",
    "    response = requests.post(url, json={'query': query, 'variables': variables})\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        all_data.extend(data['data']['Page']['media'])\n",
    "        pageInfo = data['data']['Page']['pageInfo']\n",
    "        if not pageInfo['hasNextPage']:\n",
    "            break\n",
    "        variables['page'] += 1  # Increment the page number for the next request\n",
    "    else:\n",
    "        print(f\"Failed to fetch data: {response.status_code}\")\n",
    "        print(f\"Error message: {response.text}\")\n",
    "\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataframe from the API data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_df = pd.DataFrame(all_data)\n",
    "api_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "All the data in each column are in dictionaries so we need to pull the values out of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean title column from dictionary to string\n",
    "def getTitle(t):\n",
    "    if t['english'] is not None:\n",
    "        return t['english']\n",
    "    else:\n",
    "        return t['romaji']\n",
    "    \n",
    "api_df['title'] = api_df['title'].apply(getTitle)\n",
    "api_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean date columns from dictionary to 'month-year'\n",
    "def getDate(d):\n",
    "    if isinstance(d, dict) and 'year' in d and 'month' in d:\n",
    "        if d['year'] is not None and d['month'] is not None:\n",
    "            return f\"{d['month']}-{d['year']}\"\n",
    "        elif d['year'] is not None and d['month'] is  None:\n",
    "            return f\"{d['year']}\"\n",
    "    else:\n",
    "        return None\n",
    "api_df['startDate'] = api_df['startDate'].apply(getDate)\n",
    "api_df['endDate'] = api_df['endDate'].apply(getDate)\n",
    "api_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean studio column from dictionary to string\n",
    "def getStudios(s):\n",
    "    edges = s.get('edges', [])\n",
    "    node = edges[0]['node']['name'] if edges and edges[0].get('node') else None\n",
    "    return node\n",
    "api_df['studios'] = api_df['studios'].apply(getStudios)\n",
    "api_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean rankings getting the global ranking\n",
    "def getRanking(r):\n",
    "    if len(r) > 0:\n",
    "        return r[0]['rank']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "getRanking(api_df['rankings'].iloc[0])\n",
    "api_df['rankings'] = api_df['rankings'].apply(getRanking)\n",
    "api_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean tags columns converting dictionary to array\n",
    "def convertTags(d):\n",
    "    result = []\n",
    "    if len(d) <= 0:\n",
    "        return result\n",
    "    else:\n",
    "        for dic in d:\n",
    "            if isinstance(dic, dict) and 'name' in dic:\n",
    "                result.append(dic['name'])\n",
    "        return result\n",
    "api_df.loc[:, 'tags'] = api_df['tags'].copy().apply(convertTags)\n",
    "api_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'api_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fill and remove NaN for certain columns\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# If the title of a anime doesn't exist remove the row\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m api_df \u001b[38;5;241m=\u001b[39m \u001b[43mapi_df\u001b[49m[api_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()] \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# If the rankings, popularity, or averageScore is NaN then convert to 0\u001b[39;00m\n\u001b[1;32m      7\u001b[0m api_df\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrankings\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m api_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrankings\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'api_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Fill and remove NaN for certain columns\n",
    "\n",
    "# If the title of a anime doesn't exist remove the row\n",
    "api_df = api_df[api_df['title'].notna()] \n",
    "\n",
    "# If the rankings, popularity, or averageScore is NaN then convert to 0\n",
    "api_df.loc[:, 'rankings'] = api_df['rankings'].fillna(0)\n",
    "api_df.loc[:, 'popularity'] = api_df['popularity'].fillna(0)\n",
    "api_df.loc[:, 'averageScore'] = api_df['averageScore'].fillna(0)\n",
    "\n",
    "api_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catching Edge Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN value to 'Ongoing' for status for animes that are still releasing \n",
    "api_df.loc[api_df['status'] == 'RELEASING', 'endDate'] = 'Ongoing'\n",
    "api_df[api_df['status'] == 'RELEASING']\n",
    "api_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN value for season and seasonYear to startDate values if season and seasonYear is NaN\n",
    "month_season_dict = {1: 'WINTER', 2: 'WINTER', 3: 'SPRING',\n",
    "                     4: 'SPRING', 5: 'SPRING', 6: 'SUMMER',\n",
    "                     7: 'SUMMER', 8: 'SUMMER', 9: 'FALL',\n",
    "                     10: 'FALL', 11: 'FALL', 12: 'WINTER'}\n",
    "for index, row in api_df.iterrows():\n",
    "    if pd.isnull(row['season']) or pd.isnull(row['seasonYear']):  \n",
    "        start_date = row['startDate']\n",
    "        if '-' in start_date:\n",
    "            month, year = start_date.split('-')\n",
    "            api_df.at[index, 'season'] = month_season_dict[int(month)]\n",
    "            api_df.at[index, 'seasonYear'] = year\n",
    "        else:\n",
    "            api_df.at[index, 'seasonYear'] = start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download csv file\n",
    "# (so we don't have to query the api everytime and cause a request limit)\n",
    "api_df.to_csv('anime-dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>startDate</th>\n",
       "      <th>endDate</th>\n",
       "      <th>season</th>\n",
       "      <th>seasonYear</th>\n",
       "      <th>tags</th>\n",
       "      <th>format</th>\n",
       "      <th>status</th>\n",
       "      <th>episodes</th>\n",
       "      <th>genres</th>\n",
       "      <th>popularity</th>\n",
       "      <th>averageScore</th>\n",
       "      <th>countryOfOrigin</th>\n",
       "      <th>source</th>\n",
       "      <th>studios</th>\n",
       "      <th>rankings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>4-1998</td>\n",
       "      <td>4-1999</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>['Space', 'Crime', 'Episodic', 'Ensemble Cast'...</td>\n",
       "      <td>TV</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>26.0</td>\n",
       "      <td>['Action', 'Adventure', 'Drama', 'Sci-Fi']</td>\n",
       "      <td>339045</td>\n",
       "      <td>86.0</td>\n",
       "      <td>JP</td>\n",
       "      <td>ORIGINAL</td>\n",
       "      <td>Sunrise</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cowboy Bebop: The Movie - Knockin' on Heaven's...</td>\n",
       "      <td>9-2001</td>\n",
       "      <td>9-2001</td>\n",
       "      <td>SUMMER</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>['Terrorism', 'Primarily Adult Cast', 'Crime',...</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Action', 'Drama', 'Mystery', 'Sci-Fi']</td>\n",
       "      <td>63194</td>\n",
       "      <td>82.0</td>\n",
       "      <td>JP</td>\n",
       "      <td>ORIGINAL</td>\n",
       "      <td>bones</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trigun</td>\n",
       "      <td>4-1998</td>\n",
       "      <td>9-1998</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>['Guns', 'Fugitive', 'Male Protagonist', 'Prim...</td>\n",
       "      <td>TV</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>26.0</td>\n",
       "      <td>['Action', 'Adventure', 'Comedy', 'Drama', 'Sc...</td>\n",
       "      <td>120520</td>\n",
       "      <td>79.0</td>\n",
       "      <td>JP</td>\n",
       "      <td>MANGA</td>\n",
       "      <td>MADHOUSE</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Witch Hunter ROBIN</td>\n",
       "      <td>7-2002</td>\n",
       "      <td>12-2002</td>\n",
       "      <td>SUMMER</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>['Female Protagonist', 'Police', 'Magic', 'Urb...</td>\n",
       "      <td>TV</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>26.0</td>\n",
       "      <td>['Action', 'Drama', 'Mystery', 'Supernatural']</td>\n",
       "      <td>16120</td>\n",
       "      <td>67.0</td>\n",
       "      <td>JP</td>\n",
       "      <td>ORIGINAL</td>\n",
       "      <td>Sunrise</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beet the Vandel Buster</td>\n",
       "      <td>9-2004</td>\n",
       "      <td>9-2005</td>\n",
       "      <td>FALL</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>TV</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>52.0</td>\n",
       "      <td>['Adventure', 'Fantasy', 'Supernatural']</td>\n",
       "      <td>2238</td>\n",
       "      <td>62.0</td>\n",
       "      <td>JP</td>\n",
       "      <td>MANGA</td>\n",
       "      <td>Toei Animation</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>Kurogane Communication</td>\n",
       "      <td>10-1998</td>\n",
       "      <td>3-1999</td>\n",
       "      <td>FALL</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>['Robots', 'Post-Apocalyptic', 'Artificial Int...</td>\n",
       "      <td>TV</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>24.0</td>\n",
       "      <td>['Action', 'Adventure', 'Drama', 'Sci-Fi']</td>\n",
       "      <td>1496</td>\n",
       "      <td>58.0</td>\n",
       "      <td>JP</td>\n",
       "      <td>MANGA</td>\n",
       "      <td>APPP</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>Cutie Honey</td>\n",
       "      <td>10-1973</td>\n",
       "      <td>3-1974</td>\n",
       "      <td>FALL</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>['Female Protagonist', 'Episodic', 'Shounen', ...</td>\n",
       "      <td>TV</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>25.0</td>\n",
       "      <td>['Action', 'Adventure', 'Ecchi', 'Mahou Shoujo...</td>\n",
       "      <td>5296</td>\n",
       "      <td>58.0</td>\n",
       "      <td>JP</td>\n",
       "      <td>MANGA</td>\n",
       "      <td>Toei Animation</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Space Fantasia 2001 Nights</td>\n",
       "      <td>6-1987</td>\n",
       "      <td>6-1987</td>\n",
       "      <td>SUMMER</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>['Space', 'Seinen', 'Time Skip']</td>\n",
       "      <td>OVA</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Sci-Fi']</td>\n",
       "      <td>1111</td>\n",
       "      <td>54.0</td>\n",
       "      <td>JP</td>\n",
       "      <td>MANGA</td>\n",
       "      <td>TMS Entertainment</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>Haha wo Tazunete Sanzenri</td>\n",
       "      <td>1-1976</td>\n",
       "      <td>12-1976</td>\n",
       "      <td>WINTER</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>['Classic Literature', 'Historical', 'Male Pro...</td>\n",
       "      <td>TV</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>52.0</td>\n",
       "      <td>['Adventure', 'Drama']</td>\n",
       "      <td>3560</td>\n",
       "      <td>69.0</td>\n",
       "      <td>JP</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Nippon Animation</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>Babel II: Beyond Infinity</td>\n",
       "      <td>10-2001</td>\n",
       "      <td>12-2001</td>\n",
       "      <td>FALL</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>['Shounen', 'Super Power', 'Robots', 'Military...</td>\n",
       "      <td>TV</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>13.0</td>\n",
       "      <td>['Action', 'Adventure', 'Mystery', 'Sci-Fi', '...</td>\n",
       "      <td>849</td>\n",
       "      <td>51.0</td>\n",
       "      <td>JP</td>\n",
       "      <td>MANGA</td>\n",
       "      <td>Vega Entertainment</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title startDate  endDate  \\\n",
       "0                                          Cowboy Bebop    4-1998   4-1999   \n",
       "1     Cowboy Bebop: The Movie - Knockin' on Heaven's...    9-2001   9-2001   \n",
       "2                                                Trigun    4-1998   9-1998   \n",
       "3                                    Witch Hunter ROBIN    7-2002  12-2002   \n",
       "4                                Beet the Vandel Buster    9-2004   9-2005   \n",
       "...                                                 ...       ...      ...   \n",
       "1495                             Kurogane Communication   10-1998   3-1999   \n",
       "1496                                        Cutie Honey   10-1973   3-1974   \n",
       "1497                         Space Fantasia 2001 Nights    6-1987   6-1987   \n",
       "1498                          Haha wo Tazunete Sanzenri    1-1976  12-1976   \n",
       "1499                          Babel II: Beyond Infinity   10-2001  12-2001   \n",
       "\n",
       "      season  seasonYear                                               tags  \\\n",
       "0     SPRING      1998.0  ['Space', 'Crime', 'Episodic', 'Ensemble Cast'...   \n",
       "1     SUMMER      2001.0  ['Terrorism', 'Primarily Adult Cast', 'Crime',...   \n",
       "2     SPRING      1998.0  ['Guns', 'Fugitive', 'Male Protagonist', 'Prim...   \n",
       "3     SUMMER      2002.0  ['Female Protagonist', 'Police', 'Magic', 'Urb...   \n",
       "4       FALL      2004.0                                        ['Shounen']   \n",
       "...      ...         ...                                                ...   \n",
       "1495    FALL      1998.0  ['Robots', 'Post-Apocalyptic', 'Artificial Int...   \n",
       "1496    FALL      1973.0  ['Female Protagonist', 'Episodic', 'Shounen', ...   \n",
       "1497  SUMMER      1987.0                   ['Space', 'Seinen', 'Time Skip']   \n",
       "1498  WINTER      1976.0  ['Classic Literature', 'Historical', 'Male Pro...   \n",
       "1499    FALL      2001.0  ['Shounen', 'Super Power', 'Robots', 'Military...   \n",
       "\n",
       "     format    status  episodes  \\\n",
       "0        TV  FINISHED      26.0   \n",
       "1     MOVIE  FINISHED       1.0   \n",
       "2        TV  FINISHED      26.0   \n",
       "3        TV  FINISHED      26.0   \n",
       "4        TV  FINISHED      52.0   \n",
       "...     ...       ...       ...   \n",
       "1495     TV  FINISHED      24.0   \n",
       "1496     TV  FINISHED      25.0   \n",
       "1497    OVA  FINISHED       1.0   \n",
       "1498     TV  FINISHED      52.0   \n",
       "1499     TV  FINISHED      13.0   \n",
       "\n",
       "                                                 genres  popularity  \\\n",
       "0            ['Action', 'Adventure', 'Drama', 'Sci-Fi']      339045   \n",
       "1              ['Action', 'Drama', 'Mystery', 'Sci-Fi']       63194   \n",
       "2     ['Action', 'Adventure', 'Comedy', 'Drama', 'Sc...      120520   \n",
       "3        ['Action', 'Drama', 'Mystery', 'Supernatural']       16120   \n",
       "4              ['Adventure', 'Fantasy', 'Supernatural']        2238   \n",
       "...                                                 ...         ...   \n",
       "1495         ['Action', 'Adventure', 'Drama', 'Sci-Fi']        1496   \n",
       "1496  ['Action', 'Adventure', 'Ecchi', 'Mahou Shoujo...        5296   \n",
       "1497                                         ['Sci-Fi']        1111   \n",
       "1498                             ['Adventure', 'Drama']        3560   \n",
       "1499  ['Action', 'Adventure', 'Mystery', 'Sci-Fi', '...         849   \n",
       "\n",
       "      averageScore countryOfOrigin    source             studios  rankings  \n",
       "0             86.0              JP  ORIGINAL             Sunrise      46.0  \n",
       "1             82.0              JP  ORIGINAL               bones      44.0  \n",
       "2             79.0              JP     MANGA            MADHOUSE     279.0  \n",
       "3             67.0              JP  ORIGINAL             Sunrise      24.0  \n",
       "4             62.0              JP     MANGA      Toei Animation      61.0  \n",
       "...            ...             ...       ...                 ...       ...  \n",
       "1495          58.0              JP     MANGA                APPP      30.0  \n",
       "1496          58.0              JP     MANGA      Toei Animation       0.0  \n",
       "1497          54.0              JP     MANGA   TMS Entertainment       0.0  \n",
       "1498          69.0              JP     OTHER    Nippon Animation       0.0  \n",
       "1499          51.0              JP     MANGA  Vega Entertainment      65.0  \n",
       "\n",
       "[1500 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('anime-dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the project's ethics and privacy, we will guarantee that our approach respects these issues while remaining lawful and fair. This includes addressing any ethical and privacy concerns that may develop throughout the course of our project. The data that we've suggested can carry some inherent biases in which the selection of specific variables can potentially lead us to overlook certain factors while placing excessive emphasis on others. For instance, by focusing mainly on online popularity metrics and sales figure, we might undervalue genres that are less prevalent online but have significant cultural importance and dedicated viewership in specific regions. Additionally, there could be a geographical bias, as the data might be sourced predominantly from a local US database, potentially overlooking the perspectives of other countries in an international database that represent the popularity of anime and manga in non-English speaking countries. \n",
    "\n",
    "To detect biases, our approach involves generalizing the data and creating subgroups for a more detailed exploration of data. We can actively assess the effects of cultural and regional bias, particularly when comparing the popularity of manga in different countries. Additionally, we can consider the option of building a more diverse dataset that utilizes both international and local datasets, if possible, or alternatively, acknowledge and narrow the scope of generalizations based on situational contexts. We can also incorporate new variables that can influence popularity and adjust the weight of each variable to enhance the accuracy and fairness of our analysis. Concerning potential issues related to data privacy and equitable impact in our topic area, we recognize the risk of influencing the popularity of specific manga through our research, inadvertently popularizing certain mangas or discouraging others. However, given that all the data used is publicly available, data privacy concerns are minimal.\n",
    "\n",
    "In the context of privacy, the data utilized for our project is sourced from a publicly available API, [Anilist](https://anilist.gitbook.io/anilist-apiv2-docs/). Anilist has 5 terms involving its use which include non-commercial use, prohibition of data storage service utilization, prevention of mass data collection, adherence to naming guidelines, and compliance with restrictions on competing services which our usage of the data adheres to. Furthermore, our project doesn't involve human subjects which will not violate privacy standards of leaking personal information about individuals. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Maintain open and regular communication to keep all team members informed and engaged.*\n",
    "* *Take responsibility for your contributions, acknowledging both successes and areas for improvement.*\n",
    "* *Work collaboratively, offering and seeking support to leverage the team's collective strengths.*\n",
    "* *Acknowledge the importance of personal time, promoting flexibility to enhance well-being and productivity.*\n",
    "* *Prioritize transparency, especially during busy periods, to manage expectations and maintain trust.*\n",
    "* *Cultivate a collaborative and supportive team Eevironment, prioritizing reliability, accountability, respect, openness to feedback, and a willingness to learn from mistakes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/6  |  1 PM |  Do our own research on potential topic | Find and discuss topics; Choose a topic; Start looking at related datasets; Assign group members to complete each section of the project proposal | \n",
    "| 2/20  | 1 PM  | Find datasets correponding to the different time periods we want to analyze  | Discuss which datasets we want to use and how we will compile our data; Select datasets that we want to use and assign each person to think about how we will clean the data   |\n",
    "| 2/24  | 4 PM  | Think about what datasets are compatible | Review/Edit wrangling/EDA (and review for submission); Discuss Analysis Plan  |\n",
    "| 2/25  | Before 11:59 PM  | Review project checkpoint | Turn in Checkpoint #1: Data |\n",
    "| 2/27  | 1 PM  | Think about analysis details and what we need to complete | Discuss analysis; Assign subtasks for data analysis; Complete project check-in |\n",
    "| 3/5   | 1 PM   | Review analysis and draft conclusion points | Discuss/edit full project; Assign remaining necessary tasks |\n",
    "| 3/10  | Before 11:59 PM  | Review project EDA | Turn in Checkpoint #2: EDA |\n",
    "| 3/12  | 1 PM   | Continue to work on final tasks | Review project; Discuss points of improvement |\n",
    "| 3/20  | Before 11:59 PM  | Finalize project | Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
